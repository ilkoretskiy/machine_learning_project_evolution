{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "!pip install segmentation_models\n",
    "!pip install albumentations==0.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform as sk_transform\n",
    "import skimage.filters as sk_filters\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn import model_selection\n",
    "\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DataLoader import DataLoader, make_augmentation\n",
    "from src.Model import unet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/storage/supervisely/processed\"\n",
    "ims_dir = os.path.join(base_dir, \"imgs\")\n",
    "labels_dir = os.path.join(base_dir, \"labels\")\n",
    "img_files = sorted(glob.glob(ims_dir + \"/*.*\"))\n",
    "mask_files = sorted(glob.glob(labels_dir + \"/*.png\"))\n",
    "print (f\"Masks count : {len(mask_files)};\\nImgs count : {len(img_files)};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "dataset = list(zip(img_files, mask_files))\n",
    "train_dataset, test_dataset = model_selection.train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "print(f\"Train dataset size {len(train_dataset)}; Test dataset size {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = (256, 256)\n",
    "\n",
    "training_augmentation = make_augmentation(output_size=output_size, is_validation=False)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, augmentation_fn=training_augmentation, output_size=output_size, shuffle=True)\n",
    "\n",
    "validation_augmentation = make_augmentation(output_size=output_size, is_validation=True)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, augmentation_fn=validation_augmentation, output_size=output_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 1\n",
    "model = unet_model(OUTPUT_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/storage/segmentation_training/models/best_model_full_unwrapped_from_scratch_lr00001_batch24.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure losses and compile a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCHS = 40\n",
    "# define optomizer\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "# focal_loss = sm.losses.BinaryFocalLoss()\n",
    "# total_loss = dice_loss + (1 * focal_loss)\n",
    "total_loss = dice_loss\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('/storage/training_result/models/best_model_full_unwrapped_from_scratch_lr00001_batch24.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"/storage/training_result/models/logs_full_unwrapped_from_scratch_lr00001_batch24\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = train_data_loader, \n",
    "    steps_per_epoch=len(train_data_loader), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=test_data_loader, \n",
    "    validation_steps=len(test_data_loader),\n",
    "    use_multiprocessing=False,\n",
    "    workers=1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /storage/final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/storage/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/storage/final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs, masks = test_data_loader[0]\n",
    "imgs, masks = train_data_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_res = model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch_res[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(batch_res[0].squeeze().ravel(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotmap\n",
      "  Downloading dotmap-1.3.14-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: dotmap\n",
      "Successfully installed dotmap-1.3.14\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
